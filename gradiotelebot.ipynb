{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320713884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Imagen generada y enviada con √©xito'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate\n",
    "import requests\n",
    "from cargarchatid import cargar_chat_ids\n",
    "import telebot\n",
    "from PIL import Image\n",
    "\n",
    "def redimen(input):\n",
    "    input_image_path = f\"{input}\"\n",
    "    output_image_path = \"ejemplos/ultima.png\"\n",
    "    img = Image.open(input_image_path)\n",
    "    new_width = 350\n",
    "    new_height = 350\n",
    "    resized_img = img.resize((new_width, new_height))\n",
    "    resized_img.save(output_image_path)\n",
    "\n",
    "\n",
    "class StableDiffusion(BaseTool):\n",
    "    name = \"get_imagen\"\n",
    "    description = \"Genera im√°genes digitales de alta calidad a partir de descripciones en lenguaje natural y se usa esa descripci√≥n como query\"\n",
    "    return_direct = True\n",
    "    def _run(self, query: str, text: str = None, url: str = None, description: str = None):\n",
    "        chat_ids=cargar_chat_ids()\n",
    "        for chat_id in chat_ids:\n",
    "            print(chat_id)\n",
    "        \n",
    "        bot_token = '6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg'  \n",
    "        bot = telebot.TeleBot(bot_token)\n",
    "        telebot.TeleBot(bot_token).send_message(chat_id, f\"üñºÔ∏è*Creando Imagen.....*\",parse_mode='Markdown')\n",
    "        telebot.TeleBot(bot_token).send_message(chat_id, f\"*Espere un Momento*\",parse_mode='Markdown')\n",
    "\n",
    "        url = \"https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image\"\n",
    "\n",
    "        body = {\n",
    "            \"steps\": 40,\n",
    "            \"width\": 1024,\n",
    "            \"height\": 1024,\n",
    "            \"seed\": 0,\n",
    "            \"cfg_scale\": 5,\n",
    "            \"samples\": 1,\n",
    "            \"text_prompts\": [\n",
    "                {\n",
    "                \"text\": f\"{query}\",\n",
    "                \"weight\": 1\n",
    "                },\n",
    "                {\n",
    "                \"text\": \"blurry, bad\",\n",
    "                \"weight\": -1\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": \"Bearer sk-JY7n1eptQhzGjC7jPQoSXbhKxpGwcr08liUzO3gzDWk97DeO\",\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            url,\n",
    "            headers=headers,\n",
    "            json=body,\n",
    "        )\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            out_directory = \"./photos-Stabled\"\n",
    "\n",
    "            if not os.path.exists(out_directory):\n",
    "                os.makedirs(out_directory)\n",
    "\n",
    "            for i, image in enumerate(data[\"artifacts\"]):\n",
    "                with open(f'{out_directory}/txt2img_{image[\"seed\"]}.png', \"wb\") as f:\n",
    "                    f.write(base64.b64decode(image[\"base64\"]))\n",
    "\n",
    "            with open(f'{out_directory}/txt2img_{image[\"seed\"]}.png', \"rb\") as photo:\n",
    "                bot.send_photo(chat_id, photo)\n",
    "                redimen(f'{out_directory}/txt2img_{image[\"seed\"]}.png')\n",
    "            bot.send_message(chat_id, f\"Foto de {query} creada con exito.\")\n",
    "            return \"Imagen generada y enviada con √©xito\"\n",
    "        else:\n",
    "            error_message = f\"Error en la generaci√≥n de imagen. C√≥digo de respuesta: {response.status_code}\\n{response.text}\"\n",
    "            print(error_message)\n",
    "            return error_message\n",
    "\n",
    "StableDiffusion._run(StableDiffusion,\"perro mojado comiendo helado de arcoiris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\gradioproyect\\gradiotelebot.ipynb Celda 2\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         \u001b[39m#print(enviando_mensaje)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         \u001b[39m#print(ventanaconver)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     window\u001b[39m.\u001b[39mclose()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m ventana()\n",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\gradioproyect\\gradiotelebot.ipynb Celda 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m query \u001b[39m=\u001b[39m values[\u001b[39m'\u001b[39m\u001b[39m-QUERY-\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mrstrip()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# EXECUTE YOUR COMMAND HERE\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#print(f'The command you entered was {user_input}'.format(query), flush=True)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m hay_en_conversacion \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(chat[\u001b[39m'\u001b[39m\u001b[39mestado\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39men_conversacion\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m chat \u001b[39min\u001b[39;00m conversacion\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m#xd=conversacion[chat_id]['verification_code']\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W0sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m formatted_conversation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(item\u001b[39m.\u001b[39mkeys())[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(item\u001b[39m.\u001b[39mvalues())[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m conversacion2])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl Kernel se bloque√≥ al ejecutar c√≥digo en la celda actual o en una celda anterior. Revise el c√≥digo de las celdas para identificar una posible causa del error. Haga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqu√≠</a> para obtener m√°s informaci√≥n. Vea el [registro] de Jupyter (command:jupyter.viewOutput) para obtener m√°s detalles."
     ]
    }
   ],
   "source": [
    "global last_user_input\n",
    "    image_ruta = 'qrcode.png'\n",
    "    font_size = 25\n",
    "    window_size = (1080, 1300)\n",
    "    sg.theme('DarkBrown2')\n",
    "    imagenultipath='ejemplos/ultima.png'\n",
    "\n",
    "    columna = [\n",
    "        [sg.Text(f\"Asistente de Rob√≥tica con INTELIGENCIA ARTIFICIAL:\", text_color='white', font=('Helvetica', font_size)),sg.Image(filename='logo.png', size=(50, 50), key='-IMAGE-')],\n",
    "    ]\n",
    "    column_layout  = [\n",
    "        [\n",
    "            sg.Image(filename=image_ruta, size=(250, 250), key='-IMAGE-'),\n",
    "            sg.Text(f\"C√≥digo: {verification_code}\", font=('Any', font_size), key='-LABEL-'),\n",
    "            sg.Multiline(size=(30, 20), enter_submits=False, key='-QUERY-', do_not_clear=True, autoscroll=True, font=('Helvetica', 13), text_color='black'),\n",
    "            ]\n",
    "        ]\n",
    "    columna2 = [\n",
    "        [sg.Text(f\"Descarga Telegram, escanea el c√≥digo QR para acceder al bot y luego introduce el c√≥digo de verificaci√≥n\", font=('Any', 15))],\n",
    "    ]\n",
    "    columna4 = [\n",
    "        [sg.Text(f\"Im√°genes creadas con el modelo Stable Diffusion XL1.0. \", font=('Any', 15))],\n",
    "    ]\n",
    "    columna3 = [\n",
    "        [sg.Image(filename='ejemplos/lol.png', key='-IMAGE-', size=(250, 250)), sg.Image(filename='ejemplos/ejemplo1.png', key='-IMAGE2-', size=(250, 250)),sg.Image(filename='ejemplos/ejemplo3.png', key='-IMAGE4-', size=(250, 250)),sg.Image(filename='ejemplos/helado.png', key='-IMAGE4-', size=(250, 250)),sg.Image(filename='ejemplos/caballo.png', key='-IMAGE4-', size=(250, 250))],\n",
    "    ]\n",
    "    columna5  = [\n",
    "    [\n",
    "        sg.Column([\n",
    "            [sg.Text(f\"√öltima imagen generada: \", font=('Any', 15))],\n",
    "            [sg.Image(filename=imagenultipath, key='-IMAGEul-', size=(700, 700))]\n",
    "        ]),\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    layout = [\n",
    "        [sg.Column(columna, justification='center')],\n",
    "        [sg.Column(columna2, justification='center')],\n",
    "        [sg.Column(column_layout, justification='center')],\n",
    "        #[sg.Column(columna4, justification='center')],\n",
    "        #[sg.Column(columna3, justification='center')],\n",
    "        [sg.Column(columna5, justification='center')]\n",
    "        #[sg.Button('Cerrar')]\n",
    "    ]\n",
    "   \n",
    "\n",
    "    #print(message_json)\n",
    "    window = sg.Window('GUI:', layout, finalize=True, size=window_size)\n",
    "    while True:\n",
    "        sg.set_options(suppress_error_popups =True)\n",
    "        event, values = window.read(timeout=1)  # Actualizar cada 1000 ms (1 segundo)\n",
    "        if event in (sg.WIN_CLOSED, 'Cerrar'):\n",
    "            break\n",
    "\n",
    "        formatted_conversation = '\\n\\n'.join([f\"{list(item.keys())[0]}: {list(item.values())[0]}\" for item in conversacion2])\n",
    "        window['-QUERY-'].update(formatted_conversation)\n",
    "        window['-LABEL-'].update(f\"Codigo de verificacion: {verification_code}\")\n",
    "        window['-IMAGEul-'].update(filename=imagenultipath)\n",
    "    window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_3720\\1621562735.py\", line 44, in ventana\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 9618, in __init__\n",
      "    self.Finalize()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 10304, in finalize\n",
      "    self.Read(timeout=1)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 10079, in read\n",
      "    results = self._read(timeout=timeout, timeout_key=timeout_key)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 10150, in _read\n",
      "    self._Show()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 9890, in _Show\n",
      "    StartupTK(self)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\PySimpleGUI\\PySimpleGUI.py\", line 16824, in StartupTK\n",
      "    root = tk.Toplevel(class_=window.Title)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\tkinter\\__init__.py\", line 2621, in __init__\n",
      "    BaseWidget.__init__(self, master, 'toplevel', cnf, {}, extra)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\tkinter\\__init__.py\", line 2572, in __init__\n",
      "    self.tk.call(\n",
      "RuntimeError: main thread is not in main loop\n",
      "2023-11-07 21:20:25,340 (__init__.py:966 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\n",
      "2023-11-07 21:20:25,341 (__init__.py:968 MainThread) ERROR - TeleBot: \"Break infinity polling\"\n"
     ]
    }
   ],
   "source": [
    "import PySimpleGUI as sg\n",
    "import telebot\n",
    "import threading\n",
    "import time\n",
    "\n",
    "bot_token = \"6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg\"\n",
    "\n",
    "bot = telebot.TeleBot(bot_token)\n",
    "\n",
    "\n",
    "# Funci√≥n para mostrar la ventana de PySimpleGUI\n",
    "def ventana():\n",
    "    image_ruta = 'qrcode.png'\n",
    "    font_size = 20\n",
    "    window_size = (1200, 750)\n",
    "    verification_code=2222\n",
    "    sg.theme('DarkAmber')\n",
    "    # Crea una columna para centrar la imagen y el texto\n",
    "    columna = [\n",
    "        [sg.Text(f\"Asistente de Robotica\", font=('Helvetica', font_size)),sg.Image(filename='logo.png', size=(50, 50), key='-IMAGE-')],\n",
    "    ]\n",
    "    column_layout = [\n",
    "        [sg.Image(filename=image_ruta, size=(250, 250), key='-IMAGE-'), sg.Text(f\"Codigo de Verificaci√≥n: {verification_code}\", font=('Any', font_size), key='-LABEL-'), sg.Multiline(size=(70, 30), enter_submits=True, key='-QUERY-', do_not_clear=False)],\n",
    "    ]\n",
    "    columna2 = [\n",
    "        [sg.Text(f\"Descarga telegram, escanea el QR para ingresar al bot, e ingresa el codigo de verificaci√≥n\", font=('Any', 15))],\n",
    "    ]\n",
    "    columna3 = [\n",
    "        [sg.Image(filename='ejemplos/lol.png', key='-IMAGE-', size=(250, 250)), sg.Image(filename='ejemplos/ejemplo1.png', key='-IMAGE2-', size=(250, 250)),sg.Image(filename='ejemplos/ejemplo3.png', key='-IMAGE4-', size=(250, 250))],\n",
    "    ]\n",
    "\n",
    "    layout = [\n",
    "        [sg.Column(columna, justification='center')],\n",
    "        [sg.Column(column_layout, justification='center')],\n",
    "        [sg.Column(columna2, justification='center')],\n",
    "        [sg.Column(columna3, justification='center')]\n",
    "        #[sg.Button('Cerrar')]\n",
    "    ]\n",
    "\n",
    "    button_row = [\n",
    "    # Espacio vac√≠o con el ancho de la columna\n",
    "    sg.Button('Cerrar', size=(10, 1), key='-BUTTON-', pad=(0, (0, 20)))]\n",
    "    \n",
    "    window = sg.Window('CODIGO DE VERIFICACIONES', layout, finalize=True, size=window_size)\n",
    "\n",
    "    while True:\n",
    "        event, values = window.read(timeout=1000)  # Actualizar cada 1000 ms (1 segundo)\n",
    "        \n",
    "        if event in (sg.WIN_CLOSED, 'Cerrar'):\n",
    "            break\n",
    "        \n",
    "        query = values['-QUERY-'].rstrip()\n",
    "        user_input=\"Hola\"\n",
    "\n",
    "        print(\"Pregunta:\"+{user_input}.format(query), flush=True)\n",
    "        window['-LABEL-'].update(f\"Codigo de Verificaci√≥n: {verification_code}\")\n",
    "\n",
    "    window.close()\n",
    "\n",
    "\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_message(message):\n",
    "    chat_id = message.chat.id\n",
    "    user_input = message.text\n",
    "    bot.send_message(chat_id, \"Respuesta a mensaje de Telegram\")\n",
    "    def cronometro():\n",
    "        global segundos, cronometro_corriendo\n",
    "        cronometro_corriendo = True\n",
    "        while cronometro_corriendo: \n",
    "            if segundos >= 180:\n",
    "                if cronometro_corriendo:  \n",
    "                    cronometro_corriendo = False  \n",
    "                segundos = 0  # Reinicia el contador\n",
    "            elif cronometro_corriendo:\n",
    "                print(f'Tiempo transcurrido: {segundos} segundos')\n",
    "                segundos += 1\n",
    "                time.sleep(1)\n",
    "\n",
    "    def iniciar_cronometro():\n",
    "        global cronometro_corriendo, segundos\n",
    "        if not cronometro_corriendo:\n",
    "            cronometro_corriendo = True\n",
    "            segundos = 0 \n",
    "            hilo_cronometro = threading.Thread(target=cronometro)\n",
    "            hilo_cronometro.start()\n",
    "        else:\n",
    "            while cronometro_corriendo:\n",
    "                time.sleep(1)\n",
    "\n",
    "    iniciar_cronometro()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Iniciar el hilo de la ventana PySimpleGUI\n",
    "    hilo_ventana = threading.Thread(target=ventana)\n",
    "    hilo_ventana.start()\n",
    "    bot.infinity_polling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl Kernel se bloque√≥ al ejecutar c√≥digo en la celda actual o en una celda anterior. Revise el c√≥digo de las celdas para identificar una posible causa del error. Haga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqu√≠</a> para obtener m√°s informaci√≥n. Vea el [registro] de Jupyter (command:jupyter.viewOutput) para obtener m√°s detalles."
     ]
    }
   ],
   "source": [
    "# ... (c√≥digo anterior)\n",
    "import PySimpleGUI as sg\n",
    "import telebot\n",
    "import threading\n",
    "import time\n",
    "user_input = \"\"  # Agrega esta l√≠nea para definir user_input como una variable global\n",
    "\n",
    "def ventana():\n",
    "    image_ruta = 'qrcode.png'\n",
    "    font_size = 20\n",
    "    window_size = (1200, 750)\n",
    "    sg.theme('DarkAmber')\n",
    "\n",
    "    columna = [\n",
    "        [sg.Text(f\"Asistente de Robotica\", font=('Helvetica', font_size)),sg.Image(filename='logo.png', size=(50, 50), key='-IMAGE-')],\n",
    "    ]\n",
    "    column_layout = [\n",
    "        [sg.Image(filename=image_ruta, size=(250, 250), key='-IMAGE-'), sg.Text(f\"Codigo de Verificaci√≥n: {verification_code}\", font=('Any', font_size), key='-LABEL-'), sg.Multiline(size=(70, 30), enter_submits=True, key='-QUERY-', do_not_clear=False)],\n",
    "    ]\n",
    "    columna2 = [\n",
    "        [sg.Text(f\"Descarga telegram, escanea el QR para ingresar al bot, e ingresa el codigo de verificaci√≥n\", font=('Any', 15))],\n",
    "    ]\n",
    "    columna3 = [\n",
    "        [sg.Image(filename='ejemplos/lol.png', key='-IMAGE-', size=(250, 250)), sg.Image(filename='ejemplos/ejemplo1.png', key='-IMAGE2-', size=(250, 250)),sg.Image(filename='ejemplos/ejemplo3.png', key='-IMAGE4-', size=(250, 250))],\n",
    "    ]\n",
    "\n",
    "    layout = [\n",
    "        [sg.Column(columna, justification='center')],\n",
    "        [sg.Column(column_layout, justification='center')],\n",
    "        [sg.Column(columna2, justification='center')],\n",
    "        [sg.Column(columna3, justification='center')]\n",
    "    ]\n",
    "\n",
    "    button_row = [\n",
    "        sg.Button('Cerrar', size=(10, 1), key='-BUTTON-', pad=(0, (0, 20)))\n",
    "    ]\n",
    "\n",
    "    window = sg.Window('CODIGO DE VERIFICACIONES', layout, finalize=True, size=window_size)\n",
    "\n",
    "    while True:\n",
    "        event, values = window.read(timeout=1000)\n",
    "\n",
    "        if event in (sg.WIN_CLOSED, 'Cerrar'):\n",
    "            break\n",
    "\n",
    "        global user_input\n",
    "        if user_input is not None:\n",
    "            query = values['-QUERY-'].rstrip()\n",
    "            print(f'The command you entered was {user_input}'.format(query), flush=True)\n",
    "        else:\n",
    "            query = values['-QUERY-'].rstrip()\n",
    "            print(f'The command you entered was {user_input}'.format(query), flush=True)\n",
    "\n",
    "        window['-LABEL-'].update(f\"Codigo de Verificaci√≥n: {verification_code}\")\n",
    "\n",
    "    window.close()\n",
    "\n",
    "# ... (c√≥digo posterior)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "import time\n",
    "\n",
    "# Ruta base para las im√°genes\n",
    "image_base_path = 'photos-Stabled/'  # Reemplaza con la ubicaci√≥n de tus im√°genes\n",
    "image_extension = '.png'  # Extensi√≥n de archivo de tus im√°genes\n",
    "\n",
    "# N√∫mero total de im√°genes en la secuencia\n",
    "total_images = 5\n",
    "\n",
    "font_size = 24\n",
    "window_size = (800, 600)  # Tama√±o de la ventana\n",
    "image_size = (400, 400)  # Tama√±o de la imagen\n",
    "\n",
    "layout = [\n",
    "    [sg.Image(filename='', key='-IMAGE-', size=image_size)],\n",
    "    [sg.Text('Imagen actual: 1 de 5', key='-INFO-', font=('Any', font_size))],\n",
    "    [sg.Button('Cerrar')]\n",
    "]\n",
    "\n",
    "window = sg.Window('Secuencia de Im√°genes', layout, finalize=True, size=window_size)\n",
    "\n",
    "image_index = 1\n",
    "\n",
    "while True:\n",
    "    event, values = window.read(timeout=1000)\n",
    "    \n",
    "    if event in (sg.WIN_CLOSED, 'Cerrar'):\n",
    "        break\n",
    "\n",
    "    # Carga la siguiente imagen en la secuencia\n",
    "    image_path = f'{image_base_path}imagen{image_index}{image_extension}'\n",
    "    window['-IMAGE-'].update(filename=image_path)\n",
    "\n",
    "    window['-INFO-'].update(f'Imagen actual: {image_index} de {total_images}')\n",
    "\n",
    "    # Avanza al siguiente √≠ndice de imagen\n",
    "    image_index += 1\n",
    "\n",
    "    # Vuelve al inicio si llegamos al final de la secuencia\n",
    "    if image_index > total_images:\n",
    "        image_index = 1\n",
    "\n",
    "window.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320713884\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\gradioproyect\\gradiotelebot.ipynb Celda 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#X21sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOcurri√≥ un error al enviar la foto. C√≥digo de estado HTTP: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#X21sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mImagen Generada\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#X21sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m StableDiffusion\u001b[39m.\u001b[39;49m_run(StableDiffusion,\u001b[39m\"\u001b[39;49m\u001b[39mAn astronaut riding a green horse\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\gradioproyect\\gradiotelebot.ipynb Celda 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#X21sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(imagen_local, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m photo:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#X21sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     files \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mphoto\u001b[39m\u001b[39m'\u001b[39m: photo}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#X21sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(url, data\u001b[39m=\u001b[39;49mdata, files\u001b[39m=\u001b[39;49mfiles)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#X21sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m# Verificar la respuesta\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#X21sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url, data\u001b[39m=\u001b[39mdata, json\u001b[39m=\u001b[39mjson, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m# Create the Request.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m req \u001b[39m=\u001b[39m Request(\n\u001b[0;32m    564\u001b[0m     method\u001b[39m=\u001b[39mmethod\u001b[39m.\u001b[39mupper(),\n\u001b[0;32m    565\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    573\u001b[0m     hooks\u001b[39m=\u001b[39mhooks,\n\u001b[0;32m    574\u001b[0m )\n\u001b[1;32m--> 575\u001b[0m prep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_request(req)\n\u001b[0;32m    577\u001b[0m proxies \u001b[39m=\u001b[39m proxies \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m    579\u001b[0m settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerge_environment_settings(\n\u001b[0;32m    580\u001b[0m     prep\u001b[39m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[0;32m    581\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\sessions.py:486\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    483\u001b[0m     auth \u001b[39m=\u001b[39m get_netrc_auth(request\u001b[39m.\u001b[39murl)\n\u001b[0;32m    485\u001b[0m p \u001b[39m=\u001b[39m PreparedRequest()\n\u001b[1;32m--> 486\u001b[0m p\u001b[39m.\u001b[39;49mprepare(\n\u001b[0;32m    487\u001b[0m     method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(),\n\u001b[0;32m    488\u001b[0m     url\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m     files\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mfiles,\n\u001b[0;32m    490\u001b[0m     data\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    491\u001b[0m     json\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mjson,\n\u001b[0;32m    492\u001b[0m     headers\u001b[39m=\u001b[39;49mmerge_setting(\n\u001b[0;32m    493\u001b[0m         request\u001b[39m.\u001b[39;49mheaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders, dict_class\u001b[39m=\u001b[39;49mCaseInsensitiveDict\n\u001b[0;32m    494\u001b[0m     ),\n\u001b[0;32m    495\u001b[0m     params\u001b[39m=\u001b[39;49mmerge_setting(request\u001b[39m.\u001b[39;49mparams, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams),\n\u001b[0;32m    496\u001b[0m     auth\u001b[39m=\u001b[39;49mmerge_setting(auth, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauth),\n\u001b[0;32m    497\u001b[0m     cookies\u001b[39m=\u001b[39;49mmerged_cookies,\n\u001b[0;32m    498\u001b[0m     hooks\u001b[39m=\u001b[39;49mmerge_hooks(request\u001b[39m.\u001b[39;49mhooks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhooks),\n\u001b[0;32m    499\u001b[0m )\n\u001b[0;32m    500\u001b[0m \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\models.py:368\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_method(method)\n\u001b[1;32m--> 368\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_url(url, params)\n\u001b[0;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_headers(headers)\n\u001b[0;32m    370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\models.py:439\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidURL(\u001b[39m*\u001b[39me\u001b[39m.\u001b[39margs)\n\u001b[0;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m scheme:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mraise\u001b[39;00m MissingSchema(\n\u001b[0;32m    440\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m!r}\u001b[39;00m\u001b[39m: No scheme supplied. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    441\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPerhaps you meant https://\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    442\u001b[0m     )\n\u001b[0;32m    444\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m host:\n\u001b[0;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidURL(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m!r}\u001b[39;00m\u001b[39m: No host supplied\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mMissingSchema\u001b[0m: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "from langchain.tools import BaseTool\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "from cargarchatid import cargar_chat_ids\n",
    "import telebot\n",
    "import datetime\n",
    "\n",
    "class StableDiffusion(BaseTool):\n",
    "    name = \"get_imagen\"\n",
    "    description = \"Genera im√°genes digitales de alta calidad a partir de descripciones en lenguaje natural y se usa esa descripci√≥n como query\"\n",
    "    return_direct = True\n",
    "\n",
    "    def _run(self, query: str, text: str = None, url: str = None, description: str = None):\n",
    "        chat_ids=cargar_chat_ids()\n",
    "        for chat_id in chat_ids:\n",
    "            print(chat_id)\n",
    "        bot_token = '6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg'  # Replace with your Telegram Bot token\n",
    "\n",
    "        for chat_id in chat_ids:\n",
    "            print(chat_id)\n",
    "        \n",
    "        if query is not None:\n",
    "            input_text = query\n",
    "        elif text is not None:\n",
    "            input_text = text\n",
    "        elif url is not None:\n",
    "            input_text = url\n",
    "        elif description is not None:\n",
    "            input_text = query\n",
    "        else:\n",
    "            raise ValueError(\"Se debe proporcionar 'query' o 'text' como argumento.\")\n",
    "\n",
    "        API_URL = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "        headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "        def query(payload):\n",
    "            response = requests.post(API_URL, headers=headers, json=payload)\n",
    "            return response.content\n",
    "\n",
    "        image_bytes = query({\n",
    "            \"inputs\": f\"{query}\"\n",
    "        })\n",
    "\n",
    "        # You can access the image with PIL.Image for example\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        current_time = datetime.datetime.now()\n",
    "        fecha_str = current_time.strftime(\"%d-%m-%Y\")\n",
    "        time_str = current_time.strftime(\"%H;%M;%S\")\n",
    "\n",
    "        imagen_local = f\"photos-Stabled/{fecha_str}-{time_str}.jpg\"  # El nombre con el que queremos guardarla\n",
    "\n",
    "        image.save(imagen_local)\n",
    "\n",
    "              # Crear un diccionario con los datos que se enviar√°n en el formulario\n",
    "        data = {'chat_id': chat_id}\n",
    "\n",
    "        # Abrir y enviar la foto como un archivo binario\n",
    "        with open(imagen_local, 'rb') as photo:\n",
    "            files = {'photo': photo}\n",
    "            response = requests.post(url, data=data, files=files)\n",
    "\n",
    "        # Verificar la respuesta\n",
    "        if response.status_code == 200:\n",
    "            print('La foto se envi√≥ con √©xito.')\n",
    "        else:\n",
    "            print(f'Ocurri√≥ un error al enviar la foto. C√≥digo de estado HTTP: {response.status_code}')\n",
    "\n",
    "        return \"Imagen Generada\"\n",
    "    \n",
    "StableDiffusion._run(StableDiffusion,\"An astronaut riding a green horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "API_URL = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.content\n",
    "image_bytes = query({\n",
    "\t\"inputs\": \"astronaut wild tiger\"\n",
    "})\n",
    "# You can access the image with PIL.Image for example\n",
    "\n",
    "image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "image.save(\"lol.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\gradioproyect\\gradiotelebot.ipynb Celda 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response\u001b[39m.\u001b[39mcontent\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 00:31:55,613 (__init__.py:960 MainThread) ERROR - TeleBot: \"Infinity polling exception: ('Connection aborted.', ConnectionResetError(10054, 'Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto', None, 10054, None))\"\n",
      "ERROR:TeleBot:Infinity polling exception: ('Connection aborted.', ConnectionResetError(10054, 'Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto', None, 10054, None))\n",
      "2023-11-05 00:31:55,615 (__init__.py:962 MainThread) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [WinError 10054] Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 799, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\util\\retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\packages\\six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto', None, 10054, None))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 955, in infinity_polling\n",
      "    self.polling(non_stop=True, timeout=timeout, long_polling_timeout=long_polling_timeout,\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1040, in polling\n",
      "    logger.info('Starting your bot with username: [@%s]', self.user.username)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 273, in user\n",
      "    self._user = self.get_me()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1236, in get_me\n",
      "    result = apihelper.get_me(self.token)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 196, in get_me\n",
      "    return _make_request(token, method_url)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 156, in _make_request\n",
      "    result = _get_req_session().request(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, 'Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto', None, 10054, None))\n",
      "\"\n",
      "ERROR:TeleBot:Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [WinError 10054] Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 799, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\util\\retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\packages\\six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto', None, 10054, None))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 955, in infinity_polling\n",
      "    self.polling(non_stop=True, timeout=timeout, long_polling_timeout=long_polling_timeout,\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1040, in polling\n",
      "    logger.info('Starting your bot with username: [@%s]', self.user.username)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 273, in user\n",
      "    self._user = self.get_me()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1236, in get_me\n",
      "    result = apihelper.get_me(self.token)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 196, in get_me\n",
      "    return _make_request(token, method_url)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 156, in _make_request\n",
      "    result = _get_req_session().request(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, 'Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto', None, 10054, None))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√≥digo de verificaci√≥n inicial generado: 8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 00:32:02,463 (__init__.py:966 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\n",
      "ERROR:TeleBot:Infinity polling: polling exited\n",
      "2023-11-05 00:32:02,464 (__init__.py:968 MainThread) ERROR - TeleBot: \"Break infinity polling\"\n",
      "ERROR:TeleBot:Break infinity polling\n"
     ]
    }
   ],
   "source": [
    "import telebot\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import tkinter as tk\n",
    "import random\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage, FunctionMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import initialize_agent, Tool, AgentType,AgentExecutor,OpenAIFunctionsAgent,load_tools\n",
    "from termcolor import colored\n",
    "from langchain.utilities import WikipediaAPIWrapper,OpenWeatherMapAPIWrapper\n",
    "import time  \n",
    "import threading\n",
    "#------------------------------------------------------ tools librerias ------------------------------------------------------\n",
    "from CLIMA import Weather\n",
    "from indicadores import Indicadores\n",
    "from googlesearchgpt import Google_Busqueda\n",
    "#from yolodetect import PhotoDetectionTool\n",
    "from stabledifusion import StableDiffusion\n",
    "from citywatch import Clock\n",
    "from guardadoconversacion import guardado_conversacion\n",
    "from WolframAlphaTool import WolframTool\n",
    "from chatid import guardar_chat_id\n",
    "from cargarchatid import cargar_chat_ids\n",
    "from codeguardar import cargar_code,guardar_code\n",
    "from threading import Timer\n",
    "import logging\n",
    "from multiprocessing import Process \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    wikipedia = WikipediaAPIWrapper(lang=\"en\",doc_content_chars_max=250)\n",
    "    wikipedia_tool = Tool(\n",
    "        name='wikipedia',\n",
    "        func= wikipedia.run,\n",
    "        description=\"esta herramienta es perfecta cuando necesitas buscar informaci√≥n resumida en wikipedia sobre temas, pa√≠ses o personas,etc.\")\n",
    "\n",
    "    OPENAI_API_KEY = \"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\"\n",
    "\n",
    "    # Configuraci√≥n de OpenAI GPT-3.5 Turbo\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.7,\n",
    "        openai_api_key=OPENAI_API_KEY,\n",
    "        model_name='gpt-3.5-turbo-0613',\n",
    "        max_tokens= 250\n",
    "    )\n",
    "\n",
    "\n",
    "    system_message = SystemMessage(content=\"Eres un asistente amigable, ademas respondes con emojis a cada pregunta\")\n",
    "    prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)\n",
    "\n",
    "    MEMORY_KEY = \"chat_history\"\n",
    "\n",
    "    prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "        system_message=system_message,\n",
    "        extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)])\n",
    "\n",
    "\n",
    "    memory = ConversationBufferWindowMemory(k=4,memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "    tools = ([Clock(),Weather(),Indicadores(),Google_Busqueda(),wikipedia_tool,WolframTool(),StableDiffusion()])  # TOOLS PARA DIFERENTES COSAS ,PhotoDetectionTool(),StableDiffusion()\n",
    "\n",
    "    agent = OpenAIFunctionsAgent(llm=llm, tools=tools,prompt=prompt)\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True, max_iterations=3, handle_parsing_errors=\"ERROR\", max_execution_time=90)\n",
    "\n",
    "    # Token de tu bot de Telegram\n",
    "    bot_token = \"6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg\"\n",
    "\n",
    "    # Configura el sistema de registro\n",
    "    logging.basicConfig(level=logging.INFO)  # Establece el nivel de registro a INFO\n",
    "\n",
    "    # Diccionario para realizar un seguimiento del estado de conversaci√≥n\n",
    "    conversacion = {}\n",
    "\n",
    "    # Crear una instancia del bot\n",
    "    bot = telebot.TeleBot(bot_token)\n",
    "\n",
    "\n",
    "    \n",
    "    def codigo_verificacion():\n",
    "        global verification_code\n",
    "        verification_code = random.randint(1000, 9999)\n",
    "        print(f\"C√≥digo de verificaci√≥n inicial generado: {verification_code}\")\n",
    "\n",
    "    codigo_verificacion()\n",
    "\n",
    "    # Actualizar el c√≥digo de verificaci√≥n para todos los IDs de chat\n",
    "    def actualizar_codigos_verificacion():\n",
    "        global verification_code\n",
    "        for chat_id in conversacion:\n",
    "            conversacion[chat_id]['verification_code'] = verification_code\n",
    "\n",
    "    ventana = tk.Tk()\n",
    "    ventana.title(\"Generador de C√≥digo\")\n",
    "\n",
    "    # Etiqueta para mostrar el c√≥digo\n",
    "    codigo_label = tk.Label(ventana, text=\"\", font=(\"Arial\", 18))\n",
    "    codigo_label.pack(pady=20)\n",
    "\n",
    "    # Funci√≥n para actualizar el c√≥digo de verificaci√≥n en la etiqueta\n",
    "    def actualizar_codigo():\n",
    "        while True:\n",
    "            codigo_label.config(text=f\"C√≥digo: {verification_code}\")\n",
    "            ventana.update()  # Actualizar la ventana\n",
    "            time.sleep(5)\n",
    "\n",
    "    # Funci√≥n principal de la ventana Tkinter\n",
    "    def ventana_tkinter():\n",
    "        while True:\n",
    "            codigo_label.config(text=f\"C√≥digo: {verification_code}\")\n",
    "            ventana.update()  # Actualizar la ventana\n",
    "            time.sleep(5)\n",
    "\n",
    "    # Crear un proceso para la ventana de Tkinter\n",
    "    ventana_process = Process(target=ventana_tkinter)\n",
    "    ventana_process.daemon = True\n",
    "\n",
    "    # Iniciar el proceso de la ventana de Tkinter\n",
    "    ventana_process.start()\n",
    "\n",
    "\n",
    "    # Manejar mensajes de texto\n",
    "    conversacion_en_curso = False\n",
    "    cronometro_corriendo = False\n",
    "\n",
    "\n",
    "    @bot.message_handler(func=lambda message: True)\n",
    "    def handle_message(message):\n",
    "        chat_id = message.chat.id\n",
    "        global verification_code\n",
    "        actualizar_codigos_verificacion()\n",
    "        def cronometro():\n",
    "            global segundos, cronometro_corriendo\n",
    "            while cronometro_corriendo:  # Se ejecutar√° siempre que cronometro_corriendo sea True\n",
    "                if segundos >= 12:\n",
    "                    if cronometro_corriendo:  # Verifica que cronometro_corriendo todav√≠a es True antes de ejecutar el c√≥digo\n",
    "                        agent_executor.memory.clear()  # Borra Memoria\n",
    "                        ventana.after(0, actualizar_codigo)\n",
    "                        conversacion[chat_id]['verification_code'] = verification_code\n",
    "                        conversacion[chat_id]['estado'] = 'Esperando_Verificacion'\n",
    "                        bot.send_message(chat_id, f\"Conversaci√≥n completada. Por favor, *ingrese el nuevo c√≥digo* üîê\", parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Fin de la conversaci√≥n en el chat {chat_id}.\")\n",
    "                        print (conversacion)\n",
    "                        cronometro_corriendo = False  # Cambia cronometro_corriendo a False\n",
    "                    segundos = 0  # Reinicia el contador\n",
    "                elif cronometro_corriendo:\n",
    "                    print(f'Tiempo transcurrido: {segundos} segundos')\n",
    "                    segundos += 1\n",
    "                    time.sleep(1)\n",
    "\n",
    "        def iniciar_cronometro():\n",
    "            global cronometro_corriendo, segundos\n",
    "            if not cronometro_corriendo:\n",
    "                cronometro_corriendo = True\n",
    "                segundos = 0  # Reinicia el contador\n",
    "                hilo_cronometro = threading.Thread(target=cronometro)\n",
    "                hilo_cronometro.start()\n",
    "            else:\n",
    "                while cronometro_corriendo:\n",
    "                    time.sleep(1)\n",
    "\n",
    "        user_input = message.text\n",
    "\n",
    "        global conversacion_en_curso\n",
    "        if conversacion_en_curso:\n",
    "            bot.send_message(chat_id, \"Hay un chat en conversaci√≥n. Por favor, espere su turno.\")\n",
    "        else:\n",
    "            if chat_id not in conversacion:\n",
    "                # Es una nueva conversaci√≥n, usar el c√≥digo generado al inicio y guardarlo en el diccionario\n",
    "                bot.send_message(chat_id, \"Ingresa nuevamente el c√≥digo de verificaci√≥n de 4 d√≠gitos para iniciar la conversaci√≥n.\")\n",
    "                conversacion[chat_id] = {'estado': 'Esperando_Verificacion', 'verification_code': verification_code}\n",
    "                print (conversacion)\n",
    "            else:\n",
    "                estado = conversacion[chat_id]['estado']\n",
    "                #hay_espera_verificacion = any(chat['estado'] == 'Esperando_Verificacion' for chat in conversacion.values())\n",
    "                hay_en_conversacion = any(chat['estado'] == 'en_conversacion' for chat in conversacion.values())\n",
    "\n",
    "                if estado == \"Esperando_Verificacion\":\n",
    "                    if hay_en_conversacion:\n",
    "                        bot.send_message(chat_id, \"*Hay un chat en conversaci√≥n. Por favor, espere su turno.*\",parse_mode=\"markdown\")\n",
    "                    else:\n",
    "                        verification_code = conversacion[chat_id]['verification_code']\n",
    "                        if user_input == str(verification_code):\n",
    "                            guardar_chat_id(chat_id)\n",
    "                            cargar_chat_ids()\n",
    "                            bot.send_message(chat_id, \"‚úÖ *C√≥digo correcto* - ¬°Comienza la conversaci√≥n! Dispones de *2 minutos*.\",parse_mode=\"markdown\")\n",
    "                            conversacion[chat_id]['estado'] = 'en_conversacion'\n",
    "                            conversacion[chat_id]['start_time'] = datetime.now()\n",
    "                            logging.info(f\"Inicio de la conversaci√≥n en el chat {chat_id}.\")\n",
    "                            iniciar_cronometro()\n",
    "                        else:\n",
    "                            if user_input == \"/tools\":\n",
    "                                chat_id = message.chat.id\n",
    "                                bot.send_message(chat_id, \"\"\"\\\n",
    "                            üõ†Ô∏è Herramientas\\n*Este bot dispone de las siguientes herramientas:*\\n-‚òÄÔ∏è Clima\\n-üí≤ Indicadores Econ√≥micos\\n-üîç B√∫squeda en Google\\n-üñºÔ∏è Generador de im√°genes con Stable Diffusion XL\\n-üßÆ Wolfram Alpha\\n-üï∞ Reloj\\n-üìö Wikipedia\"\"\",parse_mode=\"markdown\")\n",
    "                            elif user_input == \"/start\":\n",
    "                                chat_id = message.chat.id\n",
    "                                bot.send_message(chat_id, \"üöÄ *Bienvenido a nuestro asistente!\\n*Para comenzar, ingresa el c√≥digo que aparece en pantalla. El bot te lo solicitar√° nuevamente, y podr√°s disfrutar de una interacci√≥n de *2Ô∏è‚É£ minutos*.Recuerda que solo un usuario puede interactuar a la vez, as√≠ que si el bot no responde en alg√∫n momento, no dudes en hacer otra pregunta. ¬°Estamos aqu√≠ para ayudarte!\",parse_mode=\"markdown\")\n",
    "                            elif user_input == \"/info\":\n",
    "                                chat_id = message.chat.id\n",
    "                                bot.send_message(chat_id, \"\"\"‚ÑπÔ∏è *Informaci√≥n:*\\nEste es un ü§ñ bot con inteligencia artificial del laboratorio de rob√≥tica de la PUCV. *¬°Hazle preguntas y te responder√°!*\"\"\",parse_mode=\"markdown\")\n",
    "                            elif user_input == \"/by\":\n",
    "                                chat_id = message.chat.id\n",
    "                                bot.send_message(chat_id, \"\"\"üë§ *Creado por:*\\nCarlos Zamorano (Colaborador Lab).\"\"\",parse_mode=\"markdown\")\n",
    "                            elif user_input == \"/version\":\n",
    "                                chat_id = message.chat.id\n",
    "                                bot.send_message(chat_id, \"\"\"üìÖ Versi√≥n: *Beta 0.21*\"\"\",parse_mode=\"markdown\")\n",
    "                            else:\n",
    "                                bot.send_message(chat_id, \"C√≥digo incorrecto. Int√©ntalo de nuevo.\")\n",
    "                                print(f\"Ingresa el nuevo c√≥digo de verificaci√≥n: {verification_code}\")\n",
    "                                print (conversacion)\n",
    "                elif estado == \"en_conversacion\":\n",
    "                    print (conversacion)\n",
    "                    current_time = datetime.now()\n",
    "                    start_time = conversacion[chat_id]['start_time']\n",
    "                    elapsed_time = current_time - start_time\n",
    "                    if user_input == \"/tools\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"\"\"\\\n",
    "                    üõ†Ô∏è Herramientas\\n*Este bot dispone de las siguientes herramientas:*\\n-‚òÄÔ∏è Clima\\n-üí≤ Indicadores Econ√≥micos\\n-üîç B√∫squeda en Google\\n-üñºÔ∏è Generador de im√°genes con Stable Diffusion XL\\n-üßÆ Wolfram Alpha\\n-üï∞ Reloj\\n-üìö Wikipedia\"\"\",parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    elif user_input == \"/start\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"üöÄ *Bienvenido a nuestro asistente!\\n*Para comenzar, ingresa el c√≥digo que aparece en pantalla. El bot te lo solicitar√° nuevamente, y podr√°s disfrutar de una interacci√≥n de *2Ô∏è‚É£ minutos*.Recuerda que solo un usuario puede interactuar a la vez, as√≠ que si el bot no responde en alg√∫n momento, no dudes en hacer otra pregunta. ¬°Estamos aqu√≠ para ayudarte!\",parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    elif user_input == \"/info\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"\"\"‚ÑπÔ∏è *Informaci√≥n:*\\nEste es un ü§ñ bot con inteligencia artificial del laboratorio de rob√≥tica de la PUCV. *¬°Hazle preguntas y te responder√°!*\"\"\",parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    elif user_input == \"/by\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"\"\"üë§ *Creado por:*\\nCarlos Zamorano (Colaborador Lab).\"\"\",parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    elif user_input == \"/version\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"\"\"üìÖ Versi√≥n: *Beta 0.21*\"\"\",parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    else:\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id,agent_executor.run(user_input))\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "    bot.infinity_polling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversacion_en_curso = False\n",
    "\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_message(message):\n",
    "    chat_id = message.chat.id\n",
    "    user_input = message.text\n",
    "    global conversacion_en_curso\n",
    "\n",
    "    if conversacion_en_curso:\n",
    "        bot.send_message(chat_id, \"Hay 1 chat en conversaci√≥n. Por favor, espere su turno.\")\n",
    "    else:\n",
    "        if chat_id not in conversacion:\n",
    "            # Es una nueva conversaci√≥n, usar el c√≥digo generado al inicio y guardarlo en el diccionario\n",
    "            bot.send_message(chat_id, \"Ingresa nuevamente el c√≥digo de verificaci√≥n de 4 d√≠gitos para iniciar la conversaci√≥n.\")\n",
    "            conversacion[chat_id] = {'estado': 'Esperando_Verificacion', 'verification_code': verification_code_initial}\n",
    "        else:\n",
    "            estado = conversacion[chat_id]['estado']\n",
    "            hay_espera_verificacion = any(chat['estado'] == 'Esperando_Verificacion' for chat in conversacion.values())\n",
    "            hay_en_conversacion = any(chat['estado'] == 'en_conversacion' for chat in conversacion.values())\n",
    "\n",
    "            if estado == \"Esperando_Verificacion\":\n",
    "                if hay_en_conversacion:\n",
    "                    bot.send_message(chat_id, \"Hay un chat en conversaci√≥n. Por favor, espere su turno.\")\n",
    "                else:\n",
    "                    verification_code = conversacion[chat_id]['verification_code']\n",
    "                    if user_input == str(verification_code):\n",
    "                        guardar_chat_id(chat_id)\n",
    "                        cargar_chat_ids()\n",
    "                        bot.send_message(chat_id, \"C√≥digo correcto. Comienza la conversaci√≥n.\")\n",
    "                        conversacion[chat_id]['estado'] = 'en_conversacion'\n",
    "                        conversacion[chat_id]['start_time'] = datetime.now()\n",
    "                        logging.info(f\"Inicio de la conversaci√≥n en el chat {chat_id}.\")\n",
    "                    else:\n",
    "                        bot.send_message(chat_id, \"C√≥digo incorrecto. Int√©ntalo de nuevo.\")\n",
    "                        print(f\"Ingresa el nuevo c√≥digo de verificaci√≥n: {verification_code}\")\n",
    "            elif estado == \"en_conversacion\":\n",
    "                #class RepeatTimer(Timer):  \n",
    "                #    def run(self):  \n",
    "                #        while not self.finished.wait(self.interval):  \n",
    "                #            self.function(*self.args,**self.kwargs)\n",
    "                #timer = RepeatTimer(1,display,[''],chat_id)\n",
    "\n",
    "\n",
    "                current_time = datetime.now()\n",
    "                start_time = conversacion[chat_id]['start_time']\n",
    "                elapsed_time = current_time - start_time\n",
    "\n",
    "                if elapsed_time >= timedelta(minutes=conversation_duration):\n",
    "                    agent_executor.memory.clear() # Borra Memoria\n",
    "                    verification_code = random.randint(1000, 9999)\n",
    "                    conversacion[chat_id]['verification_code'] = verification_code\n",
    "                    conversacion[chat_id]['estado'] = 'Esperando_Verificacion'\n",
    "                    bot.send_message(chat_id, f\"Conversaci√≥n terminada, *ingrese el nuevo codigo*\", parse_mode=\"markdown\")\n",
    "                    logging.info(f\"Fin de la conversaci√≥n en el chat {chat_id}.\")\n",
    "                else:\n",
    "                    if user_input == \"/tools\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"\"\"\\\n",
    "                    üõ†Ô∏è Herramientas\\n*Este bot dispone de las siguientes herramientas:*\\n-‚òÄÔ∏è Clima\\n-üí≤ Indicadores Econ√≥micos\\n-üîç B√∫squeda en Google\\n-üñºÔ∏è Generador de im√°genes con Stable Diffusion XL\\n-üßÆ Wolfram Alpha\\n-üï∞ Reloj\\n-üìö Wikipedia\"\"\",parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    elif user_input == \"/start\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"\"\"Para empezar a utilizarlo, ingresa el c√≥digo que ves en pantalla. Te lo pedir√° nuevamente y podr√°s interactuar por 2Ô∏è‚É£ minutos con este. Solo puede interactuar un usuario a la vez.\\n*SI EL BOT NO CONTESTA EN ALGUN MOMENTO DEBE VOLVER A PREGUNTAR*\"\"\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    elif user_input == \"/info\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"\"\"‚ÑπÔ∏è *Informaci√≥n:*\\nEste es un ü§ñ bot con inteligencia artificial del laboratorio de rob√≥tica de la PUCV. *¬°Hazle preguntas y te responder√°!*\"\"\",parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    elif user_input == \"/by\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"\"\"üë§ *Creado por:*\\nCarlos Zamorano (Colaborador Lab).\"\"\",parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    elif user_input == \"/version\":\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id, \"\"\"üìÖ Versi√≥n: *Beta 0.21*\"\"\",parse_mode=\"markdown\")\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                    else:\n",
    "                        chat_id = message.chat.id\n",
    "                        bot.send_message(chat_id,agent_executor.run(user_input))\n",
    "                        logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "\n",
    "\n",
    "    bot.infinity_polling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[122321312]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Funci√≥n para guardar el chat_id del √∫ltimo usuario con el que est√° hablando y eliminar cualquier chat_id previamente guardado\n",
    "chat_id=122321312\n",
    "def guardar_chat_id(chat_id):\n",
    "    file_path = \"chatid.json\"\n",
    "\n",
    "    # Crear un diccionario con el chat_id actual\n",
    "    data = [chat_id]\n",
    "\n",
    "    # Guardar el chat_id en el archivo JSON\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(data, file)\n",
    "    return data\n",
    "guardar_chat_id(chat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√≥digo de verificaci√≥n inicial generado: 2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Inicio de la conversaci√≥n en el chat 320713884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo transcurrido: 0 segundos\n",
      "Tiempo transcurrido: 1 segundos\n",
      "Tiempo transcurrido: 2 segundos\n",
      "Tiempo transcurrido: 3 segundos\n",
      "Tiempo transcurrido: 4 segundos\n",
      "Tiempo transcurrido: 5 segundos\n",
      "Tiempo transcurrido: 6 segundos\n",
      "Tiempo transcurrido: 7 segundos\n",
      "Tiempo transcurrido: 8 segundos\n",
      "Tiempo transcurrido: 9 segundos\n",
      "Ingresa el nuevo c√≥digo de verificaci√≥n: 6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fin de la conversaci√≥n en el chat 320713884.\n",
      "INFO:root:Inicio de la conversaci√≥n en el chat 320713884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo transcurrido: 0 segundos\n",
      "Tiempo transcurrido: 1 segundos\n",
      "Tiempo transcurrido: 2 segundos\n",
      "Tiempo transcurrido: 3 segundos\n",
      "Tiempo transcurrido: 4 segundos\n",
      "Tiempo transcurrido: 5 segundos\n",
      "Tiempo transcurrido: 6 segundos\n",
      "Tiempo transcurrido: 7 segundos\n",
      "Tiempo transcurrido: 8 segundos\n",
      "Tiempo transcurrido: 9 segundos\n",
      "Ingresa el nuevo c√≥digo de verificaci√≥n: 2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fin de la conversaci√≥n en el chat 320713884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingresa el nuevo c√≥digo de verificaci√≥n: 2393\n",
      "Ingresa el nuevo c√≥digo de verificaci√≥n: 2393\n",
      "Ingresa el nuevo c√≥digo de verificaci√≥n: 2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-04 16:03:55,957 (__init__.py:966 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\n",
      "ERROR:TeleBot:Infinity polling: polling exited\n",
      "2023-11-04 16:03:55,959 (__init__.py:968 MainThread) ERROR - TeleBot: \"Break infinity polling\"\n",
      "ERROR:TeleBot:Break infinity polling\n"
     ]
    }
   ],
   "source": [
    "import telebot\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import random\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage, FunctionMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import initialize_agent, Tool, AgentType,AgentExecutor,OpenAIFunctionsAgent,load_tools\n",
    "from termcolor import colored\n",
    "from langchain.utilities import WikipediaAPIWrapper,OpenWeatherMapAPIWrapper\n",
    "import time  \n",
    "import json\n",
    "import os\n",
    "import threading\n",
    "#------------------------------------------------------ tools librerias ------------------------------------------------------\n",
    "from CLIMA import Weather\n",
    "from indicadores import Indicadores\n",
    "from googlesearchgpt import Google_Busqueda\n",
    "#from yolodetect import PhotoDetectionTool\n",
    "from stabledifusion import StableDiffusion\n",
    "from citywatch import Clock\n",
    "from guardadoconversacion import guardado_conversacion\n",
    "from WolframAlphaTool import WolframTool\n",
    "from chatid import guardar_chat_id\n",
    "from cargarchatid import cargar_chat_ids\n",
    "from threading import Timer\n",
    "wikipedia = WikipediaAPIWrapper(lang=\"en\",doc_content_chars_max=250)\n",
    "wikipedia_tool = Tool(\n",
    "    name='wikipedia',\n",
    "    func= wikipedia.run,\n",
    "    description=\"esta herramienta es perfecta cuando necesitas buscar informaci√≥n resumida en wikipedia sobre temas, pa√≠ses o personas,etc.\")\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "# Configuraci√≥n de OpenAI GPT-3.5 Turbo\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo-0613',\n",
    "    max_tokens= 250\n",
    ")\n",
    "\n",
    "\n",
    "system_message = SystemMessage(content=\"Eres un asistente amigable, ademas respondes con emojis a cada pregunta\")\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)])\n",
    "\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=4,memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "tools = ([Clock(),Weather(),Indicadores(),Google_Busqueda(),wikipedia_tool,WolframTool(),StableDiffusion()])  # TOOLS PARA DIFERENTES COSAS ,PhotoDetectionTool(),StableDiffusion()\n",
    "\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools,prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True, max_iterations=3, handle_parsing_errors=\"ERROR\", max_execution_time=90)\n",
    "\n",
    "# Token de tu bot de Telegram\n",
    "bot_token = \"6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg\"\n",
    "\n",
    "# Configura el sistema de registro\n",
    "logging.basicConfig(level=logging.INFO)  # Establece el nivel de registro a INFO\n",
    "\n",
    "# Diccionario para realizar un seguimiento del estado de conversaci√≥n\n",
    "conversacion = {}\n",
    "\n",
    "# Duraci√≥n de la conversaci√≥n en minutos\n",
    "conversation_duration = 2\n",
    "\n",
    "# Crear una instancia del bot\n",
    "bot = telebot.TeleBot(bot_token)\n",
    "  \n",
    "\n",
    "# Generar un c√≥digo de verificaci√≥n al inicio\n",
    "verification_code_initial = random.randint(1000, 9999)\n",
    "print(f\"C√≥digo de verificaci√≥n inicial generado: {verification_code_initial}\")\n",
    "\n",
    "# Manejar mensajes de texto\n",
    "conversacion_en_curso = False\n",
    "cronometro_corriendo = False\n",
    "\n",
    "\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_message(message):\n",
    "    chat_id = message.chat.id\n",
    "\n",
    "    def cronometro():\n",
    "        global segundos, cronometro_corriendo\n",
    "        while cronometro_corriendo:  # Se ejecutar√° siempre que cronometro_corriendo sea True\n",
    "            if segundos >= 120:\n",
    "                if cronometro_corriendo:  # Verifica que cronometro_corriendo todav√≠a es True antes de ejecutar el c√≥digo\n",
    "                    agent_executor.memory.clear()  # Borra Memoria\n",
    "                    verification_code = random.randint(1000, 9999)\n",
    "                    print(f\"Ingresa el nuevo c√≥digo de verificaci√≥n: {verification_code}\")\n",
    "                    conversacion[chat_id]['verification_code'] = verification_code\n",
    "                    conversacion[chat_id]['estado'] = 'Esperando_Verificacion'\n",
    "                    bot.send_message(chat_id, f\"Conversaci√≥n terminada, *ingrese el nuevo c√≥digo*\", parse_mode=\"markdown\")\n",
    "                    logging.info(f\"Fin de la conversaci√≥n en el chat {chat_id}.\")\n",
    "                    cronometro_corriendo = False  # Cambia cronometro_corriendo a False\n",
    "                segundos = 0  # Reinicia el contador\n",
    "            elif cronometro_corriendo:\n",
    "                print(f'Tiempo transcurrido: {segundos} segundos')\n",
    "                segundos += 1\n",
    "                time.sleep(1)\n",
    "\n",
    "    def iniciar_cronometro():\n",
    "        global cronometro_corriendo, segundos\n",
    "        if not cronometro_corriendo:\n",
    "            cronometro_corriendo = True\n",
    "            segundos = 0  # Reinicia el contador\n",
    "            hilo_cronometro = threading.Thread(target=cronometro)\n",
    "            hilo_cronometro.start()\n",
    "        else:\n",
    "            while cronometro_corriendo:\n",
    "                time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "    user_input = message.text\n",
    "    global conversacion_en_curso\n",
    "    if conversacion_en_curso:\n",
    "        bot.send_message(chat_id, \"Hay un chat en conversaci√≥n. Por favor, espere su turno.\")\n",
    "    else:\n",
    "        # Resto de tu c√≥digo dentro de la funci√≥n handle_message\n",
    "\n",
    "        if chat_id not in conversacion:\n",
    "            # Es una nueva conversaci√≥n, usar el c√≥digo generado al inicio y guardarlo en el diccionario\n",
    "            bot.send_message(chat_id, \"Ingresa nuevamente el c√≥digo de verificaci√≥n de 4 d√≠gitos para iniciar la conversaci√≥n.\")\n",
    "            conversacion[chat_id] = {'estado': 'Esperando_Verificacion', 'verification_code': verification_code_initial}\n",
    "        else:\n",
    "            estado = conversacion[chat_id]['estado']\n",
    "            hay_espera_verificacion = any(chat['estado'] == 'Esperando_Verificacion' for chat in conversacion.values())\n",
    "            hay_en_conversacion = any(chat['estado'] == 'en_conversacion' for chat in conversacion.values())\n",
    "\n",
    "            if estado == \"Esperando_Verificacion\":\n",
    "                if hay_en_conversacion:\n",
    "                    bot.send_message(chat_id, \"Hay un chat en conversaci√≥n. Por favor, espere su turno.\")\n",
    "                else:\n",
    "                    verification_code = conversacion[chat_id]['verification_code']\n",
    "                    if user_input == str(verification_code):\n",
    "                        guardar_chat_id(chat_id)\n",
    "                        cargar_chat_ids()\n",
    "                        bot.send_message(chat_id, \"C√≥digo correcto. Comienza la conversaci√≥n.\")\n",
    "                        conversacion[chat_id]['estado'] = 'en_conversacion'\n",
    "                        conversacion[chat_id]['start_time'] = datetime.now()\n",
    "                        logging.info(f\"Inicio de la conversaci√≥n en el chat {chat_id}.\")\n",
    "                        iniciar_cronometro()\n",
    "                    else:\n",
    "                        bot.send_message(chat_id, \"C√≥digo incorrecto. Int√©ntalo de nuevo.\")\n",
    "                        print(f\"Ingresa el nuevo c√≥digo de verificaci√≥n: {verification_code}\")\n",
    "            elif estado == \"en_conversacion\":\n",
    "                current_time = datetime.now()\n",
    "                start_time = conversacion[chat_id]['start_time']\n",
    "                elapsed_time = current_time - start_time\n",
    "                if user_input == \"/tools\":\n",
    "                    chat_id = message.chat.id\n",
    "                    bot.send_message(chat_id, \"\"\"\\\n",
    "                üõ†Ô∏è Herramientas\\n*Este bot dispone de las siguientes herramientas:*\\n-‚òÄÔ∏è Clima\\n-üí≤ Indicadores Econ√≥micos\\n-üîç B√∫squeda en Google\\n-üñºÔ∏è Generador de im√°genes con Stable Diffusion XL\\n-üßÆ Wolfram Alpha\\n-üï∞ Reloj\\n-üìö Wikipedia\"\"\",parse_mode=\"markdown\")\n",
    "                    logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                elif user_input == \"/start\":\n",
    "                    chat_id = message.chat.id\n",
    "                    bot.send_message(chat_id, \"\"\"Para empezar a utilizarlo, ingresa el c√≥digo que ves en pantalla. Te lo pedir√° nuevamente y podr√°s interactuar por 2Ô∏è‚É£ minutos con este. Solo puede interactuar un usuario a la vez.\\n*SI EL BOT NO CONTESTA EN ALGUN MOMENTO DEBE VOLVER A PREGUNTAR*\"\"\")\n",
    "                    logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                elif user_input == \"/info\":\n",
    "                    chat_id = message.chat.id\n",
    "                    bot.send_message(chat_id, \"\"\"‚ÑπÔ∏è *Informaci√≥n:*\\nEste es un ü§ñ bot con inteligencia artificial del laboratorio de rob√≥tica de la PUCV. *¬°Hazle preguntas y te responder√°!*\"\"\",parse_mode=\"markdown\")\n",
    "                    logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                elif user_input == \"/by\":\n",
    "                    chat_id = message.chat.id\n",
    "                    bot.send_message(chat_id, \"\"\"üë§ *Creado por:*\\nCarlos Zamorano (Colaborador Lab).\"\"\",parse_mode=\"markdown\")\n",
    "                    logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                elif user_input == \"/version\":\n",
    "                    chat_id = message.chat.id\n",
    "                    bot.send_message(chat_id, \"\"\"üìÖ Versi√≥n: *Beta 0.21*\"\"\",parse_mode=\"markdown\")\n",
    "                    logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "                else:\n",
    "                    chat_id = message.chat.id\n",
    "                    bot.send_message(chat_id,agent_executor.run(user_input))\n",
    "                    logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "\n",
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiTelegramException",
     "evalue": "A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: chat not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApiTelegramException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\gradioproyect\\gradiotelebot.ipynb Celda 5\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError al ejecutar\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m telebot\u001b[39m.\u001b[39mTeleBot(bot_token)\u001b[39m.\u001b[39msend_message(chat_id, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Imagen de *__\u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m__*.\u001b[39m\u001b[39m\"\u001b[39m, parse_mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMarkdown\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m StableDiffusion\u001b[39m.\u001b[39;49m_run(StableDiffusion,\u001b[39m\"\u001b[39;49m\u001b[39mA beautiful landscape photo\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\gradioproyect\\gradiotelebot.ipynb Celda 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m chat_id\u001b[39m=\u001b[39mcargar_chat_ids()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m bot_token \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m telebot\u001b[39m.\u001b[39;49mTeleBot(bot_token)\u001b[39m.\u001b[39;49msend_message(chat_id, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m  *__Creando Imagen.....__*\u001b[39;49m\u001b[39m\"\u001b[39;49m,parse_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mMarkdown\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Ejecutar el modelo de Replicate\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m output \u001b[39m=\u001b[39m replicate\u001b[39m.\u001b[39mrun(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstability-ai/sdxl:2a865c9a94c9992b6689365b75db2d678d5022505ed3f63a5f53929a31a46947\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py:1549\u001b[0m, in \u001b[0;36mTeleBot.send_message\u001b[1;34m(self, chat_id, text, parse_mode, entities, disable_web_page_preview, disable_notification, protect_content, reply_to_message_id, allow_sending_without_reply, reply_markup, timeout, message_thread_id)\u001b[0m\n\u001b[0;32m   1545\u001b[0m protect_content \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprotect_content \u001b[39mif\u001b[39;00m (protect_content \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39melse\u001b[39;00m protect_content\n\u001b[0;32m   1546\u001b[0m allow_sending_without_reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_sending_without_reply \u001b[39mif\u001b[39;00m (allow_sending_without_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39melse\u001b[39;00m allow_sending_without_reply\n\u001b[0;32m   1548\u001b[0m \u001b[39mreturn\u001b[39;00m types\u001b[39m.\u001b[39mMessage\u001b[39m.\u001b[39mde_json(\n\u001b[1;32m-> 1549\u001b[0m     apihelper\u001b[39m.\u001b[39;49msend_message(\n\u001b[0;32m   1550\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken, chat_id, text, disable_web_page_preview, reply_to_message_id,\n\u001b[0;32m   1551\u001b[0m         reply_markup, parse_mode, disable_notification, timeout,\n\u001b[0;32m   1552\u001b[0m         entities, allow_sending_without_reply, protect_content\u001b[39m=\u001b[39;49mprotect_content, message_thread_id\u001b[39m=\u001b[39;49mmessage_thread_id))\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py:264\u001b[0m, in \u001b[0;36msend_message\u001b[1;34m(token, chat_id, text, disable_web_page_preview, reply_to_message_id, reply_markup, parse_mode, disable_notification, timeout, entities, allow_sending_without_reply, protect_content, message_thread_id)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39mif\u001b[39;00m message_thread_id:\n\u001b[0;32m    263\u001b[0m     payload[\u001b[39m'\u001b[39m\u001b[39mmessage_thread_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m message_thread_id\n\u001b[1;32m--> 264\u001b[0m \u001b[39mreturn\u001b[39;00m _make_request(token, method_url, params\u001b[39m=\u001b[39;49mpayload, method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py:162\u001b[0m, in \u001b[0;36m_make_request\u001b[1;34m(token, method_name, method, params, files)\u001b[0m\n\u001b[0;32m    156\u001b[0m     result \u001b[39m=\u001b[39m _get_req_session()\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m    157\u001b[0m         method, request_url, params\u001b[39m=\u001b[39mparams, files\u001b[39m=\u001b[39mfiles,\n\u001b[0;32m    158\u001b[0m         timeout\u001b[39m=\u001b[39m(connect_timeout, read_timeout), proxies\u001b[39m=\u001b[39mproxy)\n\u001b[0;32m    160\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mThe server returned: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(result\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m)))\n\u001b[1;32m--> 162\u001b[0m json_result \u001b[39m=\u001b[39m _check_result(method_name, result)\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m json_result:\n\u001b[0;32m    164\u001b[0m     \u001b[39mreturn\u001b[39;00m json_result[\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py:189\u001b[0m, in \u001b[0;36m_check_result\u001b[1;34m(method_name, result)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:    \n\u001b[0;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result_json[\u001b[39m'\u001b[39m\u001b[39mok\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m--> 189\u001b[0m         \u001b[39mraise\u001b[39;00m ApiTelegramException(method_name, result, result_json)\n\u001b[0;32m    191\u001b[0m     \u001b[39mreturn\u001b[39;00m result_json\n",
      "\u001b[1;31mApiTelegramException\u001b[0m: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: chat not found"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "from langchain.tools import BaseTool\n",
    "from PIL import Image\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate\n",
    "import requests\n",
    "import replicate\n",
    "import requests\n",
    "import telebot\n",
    "from cargarchatid import cargar_chat_ids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class StableDiffusion(BaseTool):\n",
    "    name = \"get_imagen\"\n",
    "    description = \"Genera im√°genes digitales de alta calidad a partir de descripciones en lenguaje natural y se usa esa descripci√≥n como query\"\n",
    "    def _run(self, query: str, text: str = None, url: str = None, description: str = None):\n",
    "        if query is not None:\n",
    "            input_text = query\n",
    "        elif text is not None:\n",
    "            input_text = text\n",
    "        elif url is not None:\n",
    "            input_text = url\n",
    "        elif description is not None:\n",
    "            input_text = query\n",
    "        else:\n",
    "            raise ValueError(\"Se debe proporcionar 'query' o 'text' como argumento.\")\n",
    "\n",
    "        chat_id=cargar_chat_ids()\n",
    "        bot_token = '6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg'\n",
    "        telebot.TeleBot(bot_token).send_message(chat_id, f\"  *__Creando Imagen.....__*\",parse_mode='Markdown')\n",
    "        # Ejecutar el modelo de Replicate\n",
    "        output = replicate.run(\n",
    "            \"stability-ai/sdxl:2a865c9a94c9992b6689365b75db2d678d5022505ed3f63a5f53929a31a46947\",\n",
    "            input={\n",
    "                \"width\": 768,\n",
    "                \"height\": 768,\n",
    "                \"prompt\": f\"{query}\",\n",
    "                \"refine\": \"expert_ensemble_refiner\",\n",
    "                \"scheduler\": \"K_EULER\",\n",
    "                \"lora_scale\": 0.6,\n",
    "                \"num_outputs\": 1,\n",
    "                \"guidance_scale\": 7.5,\n",
    "                \"apply_watermark\": False,\n",
    "                \"high_noise_frac\": 0.8,\n",
    "                \"negative_prompt\": \"\",\n",
    "                \"prompt_strength\": 0.8,\n",
    "                \"num_inference_steps\": 25\n",
    "            }\n",
    "        )\n",
    "\n",
    "        image=output[0]\n",
    "\n",
    "        # Luego, ejecuta el enlace URL\n",
    "        url = f\"https://api.telegram.org/bot6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg/sendPhoto?chat_id={chat_id}&photo={image}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Verificar si la solicitud al enlace URL fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            print(\"Enlace imagen enviada exitosamente\")\n",
    "        else:\n",
    "            print(\"Error al ejecutar\")\n",
    "        return telebot.TeleBot(bot_token).send_message(chat_id, f\" Imagen de *__{query}__*.\", parse_mode=\"Markdown\")\n",
    "\n",
    "StableDiffusion._run(StableDiffusion,\"A beautiful landscape photo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://replicate.delivery/pbxt/qvwUM2L7BErADJknGk05lBzuFvWrADaeKsgp1F8e6cycsD0RA/out-0.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import telebot\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage, FunctionMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import initialize_agent, Tool, AgentType,AgentExecutor,OpenAIFunctionsAgent,load_tools\n",
    "from termcolor import colored\n",
    "from langchain.utilities import WikipediaAPIWrapper,OpenWeatherMapAPIWrapper\n",
    "from pydub.playback import play\n",
    "import time\n",
    "import threading\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import torch\n",
    "import pyaudio\n",
    "import string\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "#------------------------------------------------------ tools librerias ------------------------------------------------------\n",
    "from qrgenerator import QR_GENERATOR\n",
    "from CLIMA import Weather\n",
    "from indicadores import Indicadores\n",
    "from googlesearchgpt import Google_Busqueda\n",
    "#from yolodetect import PhotoDetectionTool\n",
    "from ChromeOpen import ChromeOpen\n",
    "#from stabledifusion import StableDiffusion\n",
    "from citywatch import Clock\n",
    "from guardadoconversacion import guardado_conversacion\n",
    "from WolframAlphaTool import WolframTool\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper(lang=\"en\",doc_content_chars_max=400)\n",
    "wikipedia_tool = Tool(\n",
    "    name='wikipedia',\n",
    "    func= wikipedia.run,\n",
    "    description=\"esta herramienta es perfecta cuando necesitas buscar informaci√≥n resumida en wikipedia sobre temas, pa√≠ses o personas. proporciona res√∫menes precisos y breves que te permiten obtener informaci√≥n esencial de forma r√°pida. ya sea para investigar un tema, planificar un viaje o conocer a una figura importante, esta herramienta simplifica la b√∫squeda y te ofrece un acceso r√°pido a conocimientos clave de wikipedia.\"\n",
    "        \"cuando realizes una busqueda la debes realizar en espa√±ol\")\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "# Configuraci√≥n de OpenAI GPT-3.5 Turbo\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo-0613',\n",
    "    max_tokens= 500\n",
    ")\n",
    "\n",
    "system_message = SystemMessage(content=\"Eres un asistente amigable\")\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)])\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=4,memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "tools = ([Clock(),Weather(),Indicadores(),QR_GENERATOR(),Google_Busqueda(),ChromeOpen(),wikipedia_tool,WolframTool()])  # TOOLS PARA DIFERENTES COSAS ,PhotoDetectionTool(),StableDiffusion()\n",
    "\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools,prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True, max_iterations=5, handle_parsing_errors=\"ERROR\", max_execution_time=15)\n",
    "#respuesta = agent_executor.run(message)\n",
    "#with get_openai_callback() as cb:\n",
    "    #respuesta = agent_executor.run(message)\n",
    "    #print(f\"\\nTokens usados: {cb.total_tokens}, Costo: ${cb.total_cost}\")\n",
    "random.randrange(1000, 9999, 1)\n",
    "\n",
    "\n",
    "\n",
    "@bot.message_handler(func=lambda message:True)\n",
    "def inicio_linea(message):\n",
    "    chat_id = message.chat.id\n",
    "    bot.send_message(chat_id,agent_executor.run(message.text))\n",
    "    print(message.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bot.infinity_polling()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√≥digo de verificaci√≥n inicial generado: 5398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Inicio de la conversaci√≥n en el chat 320713884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTu chat_id es 320713884.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Tiempo transcurrido en el chat 320713884: 0:00:04.872799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHola! ¬øEn qu√© puedo ayudarte hoy?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Tiempo transcurrido en el chat 320713884: 0:00:13.125910\n",
      "2023-11-01 00:53:52,505 (__init__.py:966 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\n",
      "ERROR:TeleBot:Infinity polling: polling exited\n",
      "2023-11-01 00:53:52,507 (__init__.py:968 MainThread) ERROR - TeleBot: \"Break infinity polling\"\n",
      "ERROR:TeleBot:Break infinity polling\n"
     ]
    }
   ],
   "source": [
    "import telebot\n",
    "import random\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import random\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage, FunctionMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import initialize_agent, Tool, AgentType,AgentExecutor,OpenAIFunctionsAgent,load_tools\n",
    "from termcolor import colored\n",
    "from langchain.utilities import WikipediaAPIWrapper,OpenWeatherMapAPIWrapper\n",
    "from pydub.playback import play\n",
    "import time\n",
    "import threading\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import torch\n",
    "\n",
    "#------------------------------------------------------ tools librerias ------------------------------------------------------\n",
    "from qrgenerator import QR_GENERATOR\n",
    "from CLIMA import Weather\n",
    "from indicadores import Indicadores\n",
    "from googlesearchgpt import Google_Busqueda\n",
    "#from yolodetect import PhotoDetectionTool\n",
    "from ChromeOpen import ChromeOpen\n",
    "from stabledifusion import StableDiffusion\n",
    "from citywatch import Clock\n",
    "from guardadoconversacion import guardado_conversacion\n",
    "from WolframAlphaTool import WolframTool\n",
    "\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper(lang=\"en\",doc_content_chars_max=400)\n",
    "wikipedia_tool = Tool(\n",
    "    name='wikipedia',\n",
    "    func= wikipedia.run,\n",
    "    description=\"esta herramienta es perfecta cuando necesitas buscar informaci√≥n resumida en wikipedia sobre temas, pa√≠ses o personas. proporciona res√∫menes precisos y breves que te permiten obtener informaci√≥n esencial de forma r√°pida. ya sea para investigar un tema, planificar un viaje o conocer a una figura importante, esta herramienta simplifica la b√∫squeda y te ofrece un acceso r√°pido a conocimientos clave de wikipedia.\"\n",
    "        \"cuando realizes una busqueda la debes realizar en espa√±ol\")\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "# Configuraci√≥n de OpenAI GPT-3.5 Turbo\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo-0613',\n",
    "    max_tokens= 250\n",
    ")\n",
    "\n",
    "system_message = SystemMessage(content=\"Eres un asistente amigable\")\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)])\n",
    "\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=4,memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "tools = ([Clock(),Weather(),Indicadores(),QR_GENERATOR(),Google_Busqueda(),ChromeOpen(),wikipedia_tool,WolframTool(),StableDiffusion()])  # TOOLS PARA DIFERENTES COSAS ,PhotoDetectionTool(),StableDiffusion()\n",
    "\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools,prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True, max_iterations=3, handle_parsing_errors=\"ERROR\", max_execution_time=15)\n",
    "\n",
    "# Token de tu bot de Telegram\n",
    "bot_token = \"6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg\"\n",
    "\n",
    "# Configura el sistema de registro\n",
    "logging.basicConfig(level=logging.INFO)  # Establece el nivel de registro a INFO\n",
    "\n",
    "# Diccionario para realizar un seguimiento del estado de conversaci√≥n\n",
    "conversations = {}\n",
    "\n",
    "# Duraci√≥n de la conversaci√≥n en minutos\n",
    "conversation_duration = 1\n",
    "\n",
    "# Crear una instancia del bot\n",
    "bot = telebot.TeleBot(bot_token)\n",
    "# Generar un c√≥digo de verificaci√≥n al inicio\n",
    "verification_code_initial = random.randint(1000, 9999)\n",
    "print(f\"C√≥digo de verificaci√≥n inicial generado: {verification_code_initial}\")\n",
    "\n",
    "# Manejar mensajes de texto\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_message(message):\n",
    "    chat_id = message.chat.id\n",
    "    user_input = message.text\n",
    "    msg=(\"chat_id:\"+str(chat_id)+\"\"+user_input)\n",
    "\n",
    "    if chat_id not in conversations:\n",
    "        # Es una nueva conversaci√≥n, usar el c√≥digo generado al inicio y guardarlo en el diccionario\n",
    "        bot.send_message(chat_id, \"Ingresa el c√≥digo de verificaci√≥n de 4 d√≠gitos para iniciar la conversaci√≥n.\")\n",
    "        conversations[chat_id] = {'state': 'waiting_verification', 'verification_code': verification_code_initial}\n",
    "    else:\n",
    "        state = conversations[chat_id]['state']\n",
    "\n",
    "        if state == 'waiting_verification':\n",
    "            verification_code = conversations[chat_id]['verification_code']\n",
    "            if user_input == str(verification_code):\n",
    "                bot.send_message(chat_id, \"C√≥digo correcto. Comienza la conversaci√≥n.\")\n",
    "                conversations[chat_id]['state'] = 'in_conversation'\n",
    "                conversations[chat_id]['start_time'] = datetime.now()\n",
    "                logging.info(f\"Inicio de la conversaci√≥n en el chat {chat_id}.\")\n",
    "            else:\n",
    "                bot.send_message(chat_id, \"C√≥digo incorrecto. Int√©ntalo de nuevo.\")\n",
    "\n",
    "\n",
    "        elif state == 'in_conversation':\n",
    "            current_time = datetime.now()\n",
    "            start_time = conversations[chat_id]['start_time']\n",
    "            elapsed_time = current_time - start_time\n",
    "            if elapsed_time >= timedelta(minutes=conversation_duration):\n",
    "                # Se ha agotado el tiempo. Generar un nuevo c√≥digo y actualizar el estado de la conversaci√≥n.\n",
    "                agent_executor.memory.clear() # BORRA LA MEMORIA\n",
    "                verification_code = random.randint(1000, 9999)\n",
    "                conversations[chat_id]['verification_code'] = verification_code\n",
    "                conversations[chat_id]['state'] = 'waiting_verification'\n",
    "                print(f\"Ingresa el nuevo c√≥digo de verificaci√≥n: {verification_code}\")\n",
    "                bot.send_message(chat_id, f\"Conversaci√≥n terminada. Ingrese el nuevo codigo\")\n",
    "                logging.info(f\"Fin de la conversaci√≥n en el chat {chat_id}.\")\n",
    "                \n",
    "            else:\n",
    "                    chat_id = message.chat.id\n",
    "                    bot.send_message(chat_id,agent_executor.run(str(msg)))\n",
    "                    logging.info(f\"Tiempo transcurrido en el chat {chat_id}: {elapsed_time}\")\n",
    "\n",
    "\n",
    "bot.infinity_polling()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text_encoder\\model.safetensors not found\n",
      "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:08<00:00,  1.39s/it]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [11:52<00:00, 14.24s/it]\n",
      "c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\diffusers\\image_processor.py:88: RuntimeWarning: invalid value encountered in cast\n",
      "  images = (images * 255).round().astype(\"uint8\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La foto se envi√≥ con √©xito.\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
    "from langchain.tools import BaseTool\n",
    "import torch\n",
    "from PIL import Image\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate\n",
    "import subprocess\n",
    "import requests\n",
    "\n",
    "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([SystemMessage(content=(\"Debes crear un resumen de m√°ximo 20 palabras con la informaci√≥n que te proporciona.\")),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo-0613',\n",
    "    max_tokens=30\n",
    ")\n",
    "\n",
    "class StableDiffusion(BaseTool):\n",
    "    name = \"get_imagen\"\n",
    "    description = \"Genera im√°genes digitales de alta calidad a partir de descripciones en lenguaje natural y se usa esa descripci√≥n como query\"\n",
    "\n",
    "    def _run(self, query: str, chat_id: str, text: str = None, url: str = None, description: str = None):\n",
    "        if query is not None:\n",
    "            input_text = query\n",
    "        elif text is not None:\n",
    "            input_text = text\n",
    "        elif url is not None:\n",
    "            input_text = url\n",
    "        elif description is not None:\n",
    "            input_text = query\n",
    "        else:\n",
    "            raise ValueError(\"Se debe proporcionar 'query' o 'text' como argumento.\")\n",
    "        bot_token = '6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg'\n",
    "        \n",
    "        newquery = llm(template.format_messages(text=input_text))\n",
    "        prompt = str(newquery.content)\n",
    "        image = pipe(prompt).images[0]\n",
    "        lista = [\"/\", \":\", \"<\", \"$\", \">\", \"‚Äú\", \"|\", \"?\", \"*\"]\n",
    "\n",
    "        for char in lista:\n",
    "            if char in prompt:\n",
    "                prompt = prompt.replace(char, \"\")\n",
    "        imageFile = f'photos-Stabled/{prompt}.png'\n",
    "        image.save(imageFile)\n",
    "        msg = \"Debes responder lo siguiente y solamente eso, nada de URLS ni Links a p√°ginas externas: 'Imagen Generada'\"\n",
    "        url = f'https://api.telegram.org/bot{bot_token}/sendPhoto'\n",
    "\n",
    "        # Crear un diccionario con los datos que se enviar√°n en el formulario\n",
    "        data = {'chat_id': chat_id}\n",
    "\n",
    "        # Abrir y enviar la foto como un archivo binario\n",
    "        with open(imageFile, 'rb') as photo:\n",
    "            files = {'photo': photo}\n",
    "            response = requests.post(url, data=data, files=files)\n",
    "        \n",
    "        # Verificar la respuesta\n",
    "        if response.status_code == 200:\n",
    "            print('La foto se envi√≥ con √©xito.')\n",
    "        else:\n",
    "            print(f'Ocurri√≥ un error al enviar la foto. C√≥digo de estado HTTP: {response.status_code}')\n",
    "\n",
    "        return response\n",
    "\n",
    "response = StableDiffusion()._run(\"perro volando en una monta√±a\", \"320713884\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La foto se envi√≥ con √©xito.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "imageFile = 'photos-Stabled/a.png'\n",
    "bot_token = '6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg'\n",
    "chat_id = '320713884'\n",
    "\n",
    "url = f'https://api.telegram.org/bot{bot_token}/sendPhoto'\n",
    "\n",
    "# Crear un diccionario con los datos que se enviar√°n en el formulario\n",
    "data = {'chat_id': chat_id}\n",
    "\n",
    "# Abrir y enviar la foto como un archivo binario\n",
    "with open(imageFile, 'rb') as photo:\n",
    "    files = {'photo': photo}\n",
    "    response = requests.post(url, data=data, files=files)\n",
    "\n",
    "# Verificar la respuesta\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print('La foto se envi√≥ con √©xito.')\n",
    "else:\n",
    "    print(f'Ocurri√≥ un error al enviar la foto. C√≥digo de estado HTTP: {response.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\gradio\\helpers.py:1104: UserWarning: message here\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'respond' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\Desktop\\gradioproyect\\gradiotelebot.ipynb Celda 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m       max_token \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39mSlider(label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mM√°ximo n√∫mero tokens\u001b[39m\u001b[39m\"\u001b[39m, minimum\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, maximum\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, value\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, info\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mA m√°s n√∫meros de tokens m√°s tiempo tarda en generar una respuesta\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m       temperature \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39mSlider(label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTemperatura\u001b[39m\u001b[39m\"\u001b[39m, minimum\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, maximum\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, value\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m btn2\u001b[39m.\u001b[39mclick(respond, [msg, chatbot, max_token, temperature], [msg, chatbot])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m           \u001b[39m#Funci√≥n   Input                                   Output\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/carlo/Desktop/gradioproyect/gradiotelebot.ipynb#W2sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m msg\u001b[39m.\u001b[39msubmit(respond, [msg, chatbot, max_token, temperature], [msg, chatbot])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'respond' is not defined"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "\n",
    "import telebot\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import random\n",
    "import telebot\n",
    "import speech_recognition as sr\n",
    "import time\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage, FunctionMessage\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import initialize_agent, Tool, AgentType,AgentExecutor,OpenAIFunctionsAgent,load_tools\n",
    "from termcolor import colored\n",
    "from langchain.utilities import WikipediaAPIWrapper,OpenWeatherMapAPIWrapper\n",
    "from pydub.playback import play\n",
    "import time\n",
    "import threading\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import torch\n",
    "import pyaudio\n",
    "import string\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "#------------------------------------------------------ tools librerias ------------------------------------------------------\n",
    "from qrgenerator import QR_GENERATOR\n",
    "from CLIMA import Weather\n",
    "from indicadores import Indicadores\n",
    "from googlesearchgpt import Google_Busqueda\n",
    "#from yolodetect import PhotoDetectionTool\n",
    "from ChromeOpen import ChromeOpen\n",
    "#from stabledifusion import StableDiffusion\n",
    "from citywatch import Clock\n",
    "from guardadoconversacion import guardado_conversacion\n",
    "from WolframAlphaTool import WolframTool\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper(lang=\"en\",doc_content_chars_max=400)\n",
    "wikipedia_tool = Tool(\n",
    "    name='wikipedia',\n",
    "    func= wikipedia.run,\n",
    "    description=\"esta herramienta es perfecta cuando necesitas buscar informaci√≥n resumida en wikipedia sobre temas, pa√≠ses o personas. proporciona res√∫menes precisos y breves que te permiten obtener informaci√≥n esencial de forma r√°pida. ya sea para investigar un tema, planificar un viaje o conocer a una figura importante, esta herramienta simplifica la b√∫squeda y te ofrece un acceso r√°pido a conocimientos clave de wikipedia.\"\n",
    "        \"cuando realizes una busqueda la debes realizar en espa√±ol\")\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "# Configuraci√≥n de OpenAI GPT-3.5 Turbo\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo-0613',\n",
    "    max_tokens= 500\n",
    ")\n",
    "\n",
    "system_message = SystemMessage(content=\"Eres un asistente amigable\")\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)])\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=4,memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "tools = ([Clock(),Weather(),Indicadores(),QR_GENERATOR(),Google_Busqueda(),ChromeOpen(),wikipedia_tool,WolframTool()])  # TOOLS PARA DIFERENTES COSAS ,PhotoDetectionTool(),StableDiffusion()\n",
    "\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools,prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True, max_iterations=5, handle_parsing_errors=\"ERROR\", max_execution_time=15)\n",
    "\n",
    "\n",
    "\n",
    "theme = gr.themes.Soft(primary_hue=\"red\", secondary_hue=\"red\").set(\n",
    "    loader_color=\"#FF0000\",\n",
    "    slider_color=\"#FF0000\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "  gr.HTML(\"\"\"\n",
    "  <center>\n",
    "  <h1>Chatbot</h1>\n",
    "  </center>\n",
    "  <p style=\"text-align: left;\">El siguiente chatbot responde preguntas del curso \"Teor√≠a de Circuitos 1\" de la PUCV.</p>\n",
    "  <a href=\"https://nave13.ucv.cl\" target=\"_blank\", rel=\"noopener noreferrer\">Responder Formulario</a>\n",
    "  \"\"\")\n",
    "\n",
    "  with gr.Row():\n",
    "    with gr.Column(scale=1, min_width=900):\n",
    "\n",
    "      chatbot = gr.Chatbot()\n",
    "      msg = gr.Textbox(label=\"Prompt\", placeholder=\"Ingresa tu pregunta!!\")      #Input del usuario que es un str\n",
    "      btn2 = gr.Button(\"Enviar\")\n",
    "\n",
    "  \n",
    "\n",
    "    # Mensaje = gr.HTML(\"\"\"\n",
    "    # <center>\n",
    "    #   <h1>Especificaciones</h1>\n",
    "    # </center>\n",
    "    # \"\"\")\n",
    "    Mensaje = \"\"\n",
    "\n",
    "    with gr.Accordion(Mensaje):\n",
    "      gr.Warning('message here')\n",
    "      # gr.Markdown(\"\"\"\n",
    "      # # N√∫mero de token y Temperatura\n",
    "      # \"\"\")\n",
    "      gr.HTML(\"\"\"\n",
    "      <h1>N√∫mero de tokens y Temperatura</h1>\n",
    "      \"\"\")\n",
    "      with gr.Column(scale=1, min_width=150):\n",
    "        max_token = gr.Slider(label=\"M√°ximo n√∫mero tokens\", minimum=1, maximum=500, value=50, step=1, info=\"A m√°s n√∫meros de tokens m√°s tiempo tarda en generar una respuesta\")\n",
    "        temperature = gr.Slider(label=\"Temperatura\", minimum=0, maximum=1, value=0.7, step=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  btn2.click(respond, [msg, chatbot, max_token, temperature], [msg, chatbot])\n",
    "            #Funci√≥n   Input                                   Output\n",
    "  msg.submit(respond, [msg, chatbot, max_token, temperature], [msg, chatbot])\n",
    "\n",
    "\n",
    "demo.queue(max_size=4)\n",
    "demo.launch(share=False)\n",
    "\n",
    "\n",
    "\n",
    "# demo.launch(debug=True)\n",
    "# demo.queue(max_size=10)\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7868\n",
      "Running on public URL: https://2427509afd752d9c46.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2427509afd752d9c46.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mS√≠, Don Pollo es una cadena de restaurantes de pollo asado muy conocida en algunos pa√≠ses de Am√©rica Latina. ¬øEn qu√© puedo ayudarte relacionado con Don Pollo?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m¬°Hola! ¬øEn qu√© puedo ayudarte hoy?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_search` with `redes de computaci√≥n cu√°ntica`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{'answerBox': None, 'organic_results': [{'title': 'Computaci√≥n cu√°ntica - Wikipedia, la enciclopedia libre', 'link': 'https://es.wikipedia.org/wiki/Computaci%C3%B3n_cu%C3%A1ntica', 'snippet': 'La computaci√≥n cu√°ntica o inform√°tica cu√°ntica\\u200b es un paradigma de computaci√≥n distinto al de la inform√°tica cl√°sica. Se basa en el uso de c√∫bits (qubits en ...'}, {'title': '¬øEn qu√© consiste la computaci√≥n cu√°ntica? - Amazon AWS'}, {'title': '¬øQu√© es y c√≥mo funciona la computaci√≥n cu√°ntica? - Iberdrola'}]}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `redes de computaci√≥n cu√°ntica`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\u001b[32;1m\u001b[1;3mLa computaci√≥n cu√°ntica es un paradigma de computaci√≥n distinto al de la inform√°tica cl√°sica. Se basa en el uso de qubits (bits cu√°nticos) en lugar de bits cl√°sicos para representar y manipular informaci√≥n. Las redes de computaci√≥n cu√°ntica son sistemas que permiten la interconexi√≥n de m√∫ltiples computadoras cu√°nticas o procesadores cu√°nticos para realizar tareas computacionales de mayor complejidad.\n",
      "\n",
      "En una red de computaci√≥n cu√°ntica, los qubits de diferentes computadoras cu√°nticas pueden estar entrelazados, lo que les permite compartir y procesar informaci√≥n de manera colaborativa. Esto abre la puerta a una serie de aplicaciones y ventajas, como la resoluci√≥n m√°s r√°pida de problemas complejos, la mejora en la seguridad de las comunicaciones y el avance en √°reas como la simulaci√≥n de sistemas cu√°nticos.\n",
      "\n",
      "Actualmente, la investigaci√≥n en redes de computaci√≥n cu√°ntica se encuentra en una etapa temprana y existen varios enfoques y tecnolog√≠as en desarrollo. Algunos de los enfoques m√°s comunes incluyen la computaci√≥n cu√°ntica bas\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSoy un asistente virtual y no tengo un nombre espec√≠fico. Puedes llamarme asistente o como prefieras. ¬øEn qu√© puedo ayudarte?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mEstoy desarrollado utilizando tecnolog√≠as de procesamiento de lenguaje natural (NLP) y aprendizaje autom√°tico (Machine Learning). Estoy programado en TypeScript y utilizo el framework de OpenAI llamado OpenAI GPT-3 para generar respuestas basadas en el contexto de las preguntas y comentarios de los usuarios. Adem√°s, utilizo diversas API y servicios web para acceder a informaci√≥n actualizada y brindar respuestas precisas a las consultas de los usuarios.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `Marco Polo`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Marco Polo\n",
      "Summary: Marco Polo ( , Venetian: [Ààma…æko Ààpolo], Italian: [Ààmarko Ààp…îÀêlo] ; c.‚Äâ1254 ‚Äì  8 January 1324) was a Venetian merchant, explorer and writer who travelled through Asia along the Silk Road between 1271 and 1295. His travels are recorded in The Travels of Marco Polo (also known as Book of the Marvels of the World  and Il Milione, c.‚Äâ1300), a book that described to Europeans \u001b[0m\u001b[32;1m\u001b[1;3mMarco Polo fue un comerciante, explorador y escritor veneciano que vivi√≥ en los siglos XIII y XIV. Es conocido por sus viajes a trav√©s de Asia a lo largo de la Ruta de la Seda entre 1271 y 1295. Sus experiencias y descubrimientos se encuentran registrados en su obra \"Los viajes de Marco Polo\" (tambi√©n conocida como \"Libro de las maravillas del mundo\" o \"Il Milione\"), que fue escrita alrededor del a√±o 1300.\n",
      "\n",
      "Durante sus viajes, Marco Polo visit√≥ lugares como China, India, Persia y el Imperio Mongol, y fue testigo de la riqueza, la cultura y las costumbres de estas regiones. Sus relatos tuvieron un gran impacto en Europa, ya que proporcionaron a los europeos conocimientos detallados sobre el Lejano Oriente y despertaron un inter√©s en la exploraci√≥n y el comercio con estas tierras.\n",
      "\n",
      "Marco Polo fue uno de los primeros exploradores europeos en viajar tan lejos hacia el este y sus relatos contribuyeron significativ\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLa primera pregunta que me hiciste fue: \"puedes hacerme un informe sobre las redes que utilizan computaci√≥n cu√°ntica?\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from datetime import datetime, timedelta\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import initialize_agent, Tool, AgentType,AgentExecutor,OpenAIFunctionsAgent,load_tools\n",
    "from langchain.utilities import WikipediaAPIWrapper,OpenWeatherMapAPIWrapper\n",
    "#------------------------------------------------------ tools librerias ------------------------------------------------------\n",
    "from qrgenerator import QR_GENERATOR\n",
    "from CLIMA import Weather\n",
    "from indicadores import Indicadores\n",
    "from googlesearchgpt import Google_Busqueda\n",
    "#from yolodetect import PhotoDetectionTool\n",
    "from ChromeOpen import ChromeOpen\n",
    "#from stabledifusion import StableDiffusion\n",
    "from citywatch import Clock\n",
    "from WolframAlphaTool import WolframTool\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper(lang=\"en\",doc_content_chars_max=400)\n",
    "wikipedia_tool = Tool(\n",
    "    name='wikipedia',\n",
    "    func= wikipedia.run,\n",
    "    description=\"esta herramienta es perfecta cuando necesitas buscar informaci√≥n resumida en wikipedia sobre temas, pa√≠ses o personas. proporciona res√∫menes precisos y breves que te permiten obtener informaci√≥n esencial de forma r√°pida. ya sea para investigar un tema, planificar un viaje o conocer a una figura importante, esta herramienta simplifica la b√∫squeda y te ofrece un acceso r√°pido a conocimientos clave de wikipedia.\"\n",
    "        \"cuando realizes una busqueda la debes realizar en espa√±ol\")\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "# Configuraci√≥n de OpenAI GPT-3.5 Turbo\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo-0613',\n",
    "    max_tokens= 250\n",
    ")\n",
    "\n",
    "system_message = SystemMessage(content=\"Eres un asistente amigable\")\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)])\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=4,memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "tools = ([Clock(),Weather(),Indicadores(),QR_GENERATOR(),Google_Busqueda(),ChromeOpen(),wikipedia_tool,WolframTool()])  # TOOLS PARA DIFERENTES COSAS ,PhotoDetectionTool(),StableDiffusion()\n",
    "\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools,prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True, max_iterations=5, handle_parsing_errors=\"ERROR\", max_execution_time=15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def echo(message, history):\n",
    "    return agent_executor.run(message)\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "         image_output = gr.Image()\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(fn=echo, title=\"Echo Bot\")\n",
    "demo.queue(concurrency_count=1).launch(share=True,max_threads=1,state_session_capacity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 12:37:57,147 (__init__.py:1083 Thread-27) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message text is empty\"\n",
      "2023-10-31 12:37:57,149 (__init__.py:1085 Thread-27) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1074, in __threaded_polling\n",
      "    self.worker_pool.raise_exceptions()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\util.py\", line 147, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\util.py\", line 90, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 6801, in _run_middlewares_and_handler\n",
      "    result = handler['function'](message)\n",
      "  File \"C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_32124\\869172889.py\", line 30, in handle_message\n",
      "    bot.send_message(user_id, bot_response)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1549, in send_message\n",
      "    apihelper.send_message(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 264, in send_message\n",
      "    return _make_request(token, method_url, params=payload, method='post')\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 162, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 189, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message text is empty\n",
      "\"\n",
      "2023-10-31 12:38:05,744 (__init__.py:1083 Thread-27) ERROR - TeleBot: \"Threaded polling exception: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message text is empty\"\n",
      "2023-10-31 12:38:05,747 (__init__.py:1085 Thread-27) ERROR - TeleBot: \"Exception traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1074, in __threaded_polling\n",
      "    self.worker_pool.raise_exceptions()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\util.py\", line 147, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\util.py\", line 90, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 6801, in _run_middlewares_and_handler\n",
      "    result = handler['function'](message)\n",
      "  File \"C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_32124\\869172889.py\", line 30, in handle_message\n",
      "    bot.send_message(user_id, bot_response)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1549, in send_message\n",
      "    apihelper.send_message(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 264, in send_message\n",
      "    return _make_request(token, method_url, params=payload, method='post')\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 162, in _make_request\n",
      "    json_result = _check_result(method_name, result)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 189, in _check_result\n",
      "    raise ApiTelegramException(method_name, result, result_json)\n",
      "telebot.apihelper.ApiTelegramException: A request to the Telegram API was unsuccessful. Error code: 400. Description: Bad Request: message text is empty\n",
      "\"\n",
      "Exception in thread Thread-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [WinError 10054] Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 799, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\util\\retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\packages\\six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 715, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 467, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\urllib3\\connectionpool.py\", line 462, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\http\\client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, 'Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto', None, 10054, None))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_32124\\869172889.py\", line 33, in start_telegram_polling\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1043, in polling\n",
      "    self.__threaded_polling(non_stop=non_stop, interval=interval, timeout=timeout, long_polling_timeout=long_polling_timeout,\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1118, in __threaded_polling\n",
      "    raise e\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 1073, in __threaded_polling\n",
      "    polling_thread.raise_exceptions()\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\util.py\", line 108, in raise_exceptions\n",
      "    raise self.exception_info\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\util.py\", line 90, in run\n",
      "    task(*args, **kwargs)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 649, in __retrieve_updates\n",
      "    updates = self.get_updates(offset=(self.last_update_id + 1), \n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\__init__.py\", line 623, in get_updates\n",
      "    json_updates = apihelper.get_updates(self.token, offset, limit, timeout, allowed_updates, long_polling_timeout)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 321, in get_updates\n",
      "    return _make_request(token, method_url, params=payload)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\telebot\\apihelper.py\", line 156, in _make_request\n",
      "    result = _get_req_session().request(\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"c:\\Users\\carlo\\anaconda3\\envs\\asistente\\lib\\site-packages\\requests\\adapters.py\", line 501, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, 'Se ha forzado la interrupci√≥n de una conexi√≥n existente por el host remoto', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import telebot\n",
    "import threading\n",
    "\n",
    "# Reemplaza 'YOUR_TELEGRAM_BOT_TOKEN' con tu token de Telegram\n",
    "TOKEN = '6397055999:AAHSlOzmdu9eTRcx-cN1sRWtN6nso6X2cmg'\n",
    "\n",
    "# Inicializar la variable bot_response\n",
    "bot_response = \"\"\n",
    "\n",
    "# Configurar Gradio\n",
    "def chat_bot(message):\n",
    "    return bot_response\n",
    "\n",
    "iface = gr.Interface(fn=chat_bot, inputs=\"text\", outputs=\"text\")\n",
    "\n",
    "# Configurar el bot de Telegram\n",
    "bot = telebot.TeleBot(TOKEN)\n",
    "\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_message(message):\n",
    "    user_id = message.chat.id\n",
    "    user_message = message.text\n",
    "\n",
    "    # Procesar el mensaje del usuario\n",
    "    global bot_response  # Hacer referencia a la variable global\n",
    "    bot_response = chat_bot(user_message)  # Actualizar la respuesta de Gradio\n",
    "\n",
    "    # Enviar la respuesta de Gradio al usuario en Telegram\n",
    "    bot.send_message(user_id, bot_response)\n",
    "\n",
    "def start_telegram_polling():\n",
    "    bot.polling(none_stop=True)\n",
    "\n",
    "# Iniciar el bot de Telegram en un hilo separado\n",
    "telegram_thread = threading.Thread(target=start_telegram_polling)\n",
    "telegram_thread.daemon = True\n",
    "telegram_thread.start()\n",
    "\n",
    "# Iniciar la interfaz de Gradio\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
